{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ollama import Client\n",
    "\n",
    "load_dotenv()\n",
    "HOST_URL = os.getenv('HOST_URL')\n",
    "\n",
    "\n",
    "# api 호출\n",
    "client = Client(host=HOST_URL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다운로드 완료한 모델 목록 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(model='llava-llama3:latest', modified_at=datetime.datetime(2025, 2, 9, 7, 47, 17, 755136, tzinfo=TzInfo(UTC)), digest='44c161b1f46523301da9c0cc505afa4a4a0cc62f580581d98a430bb21acd46de', size=5545682182, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama', 'clip'], parameter_size='8B', quantization_level='Q4_K_M')),\n",
       " Model(model='erwan2/DeepSeek-Janus-Pro-7B:latest', modified_at=datetime.datetime(2025, 2, 9, 7, 27, 16, 454441, tzinfo=TzInfo(UTC)), digest='e877a212a6a7b915619769804ef20a97dd14ea59f1b1141206e9d0a6554bdd17', size=4223360703, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='6.9B', quantization_level='Q4_K_M')),\n",
       " Model(model='llama3.2-vision:latest', modified_at=datetime.datetime(2025, 2, 9, 7, 16, 13, 614472, tzinfo=TzInfo(UTC)), digest='085a1fdae525a3804ac95416b38498099c241defd0f1efc71dcca7f63190ba3d', size=7901829417, details=ModelDetails(parent_model='', format='gguf', family='mllama', families=['mllama', 'mllama'], parameter_size='9.8B', quantization_level='Q4_K_M')),\n",
       " Model(model='llama3.2-vision:90b', modified_at=datetime.datetime(2025, 2, 9, 7, 15, 15, 26828, tzinfo=TzInfo(UTC)), digest='d2a5e64c56a9cfed42fc0b8040a717e899d20646ce1ae8314bbe2e9a416f7eeb', size=54713024426, details=ModelDetails(parent_model='', format='gguf', family='mllama', families=['mllama', 'mllama'], parameter_size='87.7B', quantization_level='Q4_K_M'))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = client.list()\n",
    "models.models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순 테스트 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The image presents a pair of business cards, both resting on a light gray background. The top card is white and bears the phrase \"After glow\" in black text at the center. Just below this, there\\'s another line of text that reads \"Positive thinking\". \\n\\nBeneath these two lines, there\\'s an address written in Korean: \"서울시 강남구 신정로 1234번길\", which translates to \"Seoul City Gangnam-gu Shinjeong-ro 1234-beon-gil\".\\n\\nThe bottom card is black and features the phrase \"After glow\" at the top. Below this, there\\'s a phone number written in Korean: \"+82 2)3456789\". \\n\\nBoth cards are positioned side by side, with their respective texts facing upwards. The overall layout suggests they belong to the same individual or business entity.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ollama import Client\n",
    "\n",
    "# proxy URL을 사용하여 클라이언트 생성\n",
    "\n",
    "# 이미지를 바이너리로 읽기\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return image_file.read()\n",
    "    \n",
    "# 모델 사용 예시\n",
    "\n",
    "def test(model, question, image_path):\n",
    "    response = client.chat(model=model, \n",
    "                        messages=[\n",
    "                            {\n",
    "                                'role': 'user',\n",
    "                                'content': question,\n",
    "                                'images' : [encode_image_to_base64(image_path)]\n",
    "                            }\n",
    "                        ],\n",
    "                        options={\n",
    "                                'temperature': 0.3,      # 낮을수록 더 일관된 출력 (0.0 ~ 1.0)\n",
    "                                'top_p': 0.1,           # 낮을수록 더 집중된 출력\n",
    "                                'frequency_penalty': 0.5,  # 높을수록 반복 감소\n",
    "                                'presence_penalty': 0.5,   # 높을수록 다양한 토픽 포함\n",
    "                                'stop': ['!', '?'],  # 문장 끝에서 멈추도록 설정\n",
    "                                'max_tokens': 500        # 최대 토큰 수 제한\n",
    "                            })\n",
    "\n",
    "    return response['message']['content']\n",
    "\n",
    "\n",
    "test(\"llava-llama3\",\"이미지에 보이는걸 말해줘\", \"data/images/image_1.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n당신은 스마트 명함 관리 서비스를 위한 AI 어시스턴트입니다. 주요 기능은 명함 이미지를 처리하고, 인맥 만남에 대한 맥락 정보를 수집하며, 연락처 정보를 관리하는 것입니다. 다음 지침을 따르세요:\\n\\n1. 시스템 정의:\\n   텍스트나 이미지 데이터 형태의 사용자 입력을 받습니다. 응답은 친근하고 대화체여야 하며, 항상 새로운 정보를 처리하거나 다음 단계로 넘어갈 준비가 되어 있어야 합니다.\\n\\n2. 이미지 처리:\\n   명함 이미지를 받으면 정보를 분석하고, 다음 세부 정보를 JSON 형식으로 추출하세요:\\n   <extracted_info>\\n   {\\n     \"name\": \"\",\\n     \"position\": \"\",\\n     \"company\": \"\",\\n     \"phone\": \"\",\\n     \"email\": \"\",\\n     \"address\": \"\",\\n     \"website\": \"\",\\n     \"other_details\": []\\n   }\\n   </extracted_info>\\n\\n3. 맥락 정보 수집:\\n   이미지 처리 후, 추가 맥락 정보를 수집합니다. 예: \"이 사람을 어디서 만났나요?\", \"무엇을 논의했나요?\" 등 친근하게 물어보고, 연락처 정보에 추가합니다.\\n\\n4. 정보 요약 및 확인:\\n   추출된 명함 정보와 맥락 정보를 요약해 사용자에게 제시하고 확인을 요청하세요. 예:\\n   \"좋습니다! 새 연락처에 대해 수집한 정보는 다음과 같습니다: [요약] 이 정보가 맞나요? 추가하거나 변경하고 싶은 내용이 있나요?\"\\n\\n5. 상호작용 마무리:\\n   정보가 정확하면 \"이 연락처를 데이터베이스에 추가했습니다. 다른 명함 처리할까요?\"로 응답하고, 사용자가 \\'네\\'면 다음 이미지, \\'아니오\\'면 종료합니다.\\n\\n친근한 어조를 유지하며, 사용자의 질문이나 설명 요청에 대응하세요.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'text', 'text': '오늘 강남에서 만난 김소현 씨 명함인데, 정보 저장해줄래? '}]}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{'role': 'system', 'content': '\\n당신은 스마트 명함 관리 서비스를 위한 AI 어시스턴트입니다. 주요 기능은 명함 이미지를 처리하고, 인맥 만남에 대한 맥락 정보를 수집하며, 연락처 정보를 관리하는 것입니다. 다음 지침을 따르세요:\\n\\n1. 시스템 정의:\\n   텍스트나 이미지 데이터 형태의 사용자 입력을 받습니다. 응답은 친근하고 대화체여야 하며, 항상 새로운 정보를 처리하거나 다음 단계로 넘어갈 준비가 되어 있어야 합니다.\\n\\n2. 이미지 처리:\\n   명함 이미지를 받으면 정보를 분석하고, 다음 세부 정보를 JSON 형식으로 추출하세요:\\n   <extracted_info>\\n   {\\n     \"name\": \"\",\\n     \"position\": \"\",\\n     \"company\": \"\",\\n     \"phone\": \"\",\\n     \"email\": \"\",\\n     \"address\": \"\",\\n     \"website\": \"\",\\n     \"other_details\": []\\n   }\\n   </extracted_info>\\n\\n3. 맥락 정보 수집:\\n   이미지 처리 후, 추가 맥락 정보를 수집합니다. 예: \"이 사람을 어디서 만났나요?\", \"무엇을 논의했나요?\" 등 친근하게 물어보고, 연락처 정보에 추가합니다.\\n\\n4. 정보 요약 및 확인:\\n   추출된 명함 정보와 맥락 정보를 요약해 사용자에게 제시하고 확인을 요청하세요. 예:\\n   \"좋습니다! 새 연락처에 대해 수집한 정보는 다음과 같습니다: [요약] 이 정보가 맞나요? 추가하거나 변경하고 싶은 내용이 있나요?\"\\n\\n5. 상호작용 마무리:\\n   정보가 정확하면 \"이 연락처를 데이터베이스에 추가했습니다. 다른 명함 처리할까요?\"로 응답하고, 사용자가 \\'네\\'면 다음 이미지, \\'아니오\\'면 종료합니다.\\n\\n친근한 어조를 유지하며, 사용자의 질문이나 설명 요청에 대응하세요.\\n'}, {'role': 'user', 'content': [{'type': 'text', 'text': '오늘 강남에서 만난 김소현 씨 명함인데, 정보 저장해줄래? '}]}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
